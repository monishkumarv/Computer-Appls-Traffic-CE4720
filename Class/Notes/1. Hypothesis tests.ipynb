{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Choose Which Hypothesis Test to Use: [Link](https://youtu.be/SF1fhoz5Wxw) --- semma video ---[Websit link](https://sixsigmastudyguide.com/types-of-hypothesis-tests/#:~:text=Types%20of%20Hypothesis%20Tests%3A%20a,t%2Dtests%20compare%20two%20samples.)\n",
    "## Also try to add the image the mindmap here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does '~' mean? ---> (front ~ seasons + law (and) front ~ seasons * law)\n",
    "# Tables and read both the intro ppt for 'R'\n",
    "# Lecture slides screen shots in your phone"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- t.test - one sample (One Sample t-test)\n",
    "- t.test - two sample (Welch Two Sample t-test) - Welch’s T-test: tests for equality of means between two population samples. Also known as Welch’s unequal variances t-test.\n",
    "- var.test - two sample (F test to compare two variances)\n",
    "- bartlett.test - (Bartlett test of homogeneity of variances) - chisquared test ??\n",
    "- aov - ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the images from this site for t-test and z-tests: [Link](https://www.statisticshowto.com/standardized-test-statistic/) :Also try to add images for other tests also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Webiste + video links](https://sixsigmastudyguide.com/types-of-hypothesis-tests/#:~:text=Types%20of%20Hypothesis%20Tests%3A%20a,t%2Dtests%20compare%20two%20samples.)\n",
    "- T-test: tests for a Student’s t-distribution – ie, in a normally distributed population where standard deviation in unknown and sample size is comparatively small. Paired t-tests compare two samples.\n",
    "- Analysis of Variance (ANOVA): tests for and analyzes differences between the means in several groups. Often used similarly to a t-test, but for more than two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-score (Student's t-distribution) vs. z-score (Normal distribution):\n",
    "\n",
    "` Here population doesnt mean the sample you took. Population refers to the original distribution (a place from where you collected the sample)`\n",
    "\n",
    "- The general rule of thumb for when to use a t score is when your sample:\n",
    "    - Has a very small sample size (below 30 for example)\n",
    "    - Has an unknown population standard deviation\n",
    "    - Your data should be randomly selected from a population, where each item has an equal chance of being selected.\n",
    "\n",
    "\n",
    "- The general rule of thumb for when to use a t score is when your sample:\n",
    "    - Your sample size should be larger (above 30 for example) in order for you to be able to use the z-score. \n",
    "    - You must know the standard deviation of the population \n",
    "    - Your data should be normally distributed. However, for large sample sizes (over 30) this doesn’t always matter.\n",
    "    - Your data should be randomly selected from a population, where each item has an equal chance of being selected.\n",
    "\n",
    "`“When a sample has more than 30 observations, the normal distribution can be used in place of the t distribution.” (Meier et.al, p. 191)`\n",
    "\n",
    "<i>Note the use of the word can in the above quote; The use of the t-distribution is theoretically sound for all sample sizes, but you *can* choose to use the normal for sample above 30.\n",
    "    \n",
    "<b>Reference: [Link](https://www.statisticshowto.com/probability-and-statistics/hypothesis-testing/t-score-vs-z-score/)\n",
    "    \n",
    "` Apart from the above stated differences, they both are basically used for the same purpose`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Sample t-test:\n",
    "The one sample t test compares the mean of your sample data to a known value. For example, you might want to know how your sample mean compares to the population mean. You should run a one sample t test when you don’t know the population standard deviation or you have a small sample size.\n",
    "\n",
    "Assumptions of the test (your data should meet these requirements for the test to be valid):\n",
    "\n",
    "- Data is independent.\n",
    "- Data is collected randomly.\n",
    "- The data is approximately normally distributed.\n",
    "\n",
    "Reference with an example: [Link](https://www.statisticshowto.com/one-sample-t-test/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use a Two-Sample t-test vs. a Paired t-test\n",
    "“Independent” implies that the two samples must have come from two completely different populations. In other words, one population can’t have any bearing on the the other. If you have independent samples, you can use the two-sample t-test (also called, appropriately, the independent samples t-test). On the other hand, if your samples are connected in some way, run a paired samples t-test. “Connected” means that you are collecting data twice from the same group, person, item or thing.\n",
    "\n",
    "Examples of when to run a paired t-test:\n",
    "\n",
    "- Testing two production lines to see if their outputs are different. One line feeds into a second line, so the second line depends on the first for at least part of the production.\n",
    "- Comparing test scores for the same group of students before an intensive study session and after the session. You’re testing the same people twice, so a paired test is needed.\n",
    "- You are subjecting two different model cars to crashworthiness, using the same equipment. Although you’re testing different items, they are being subjected to the same conditions and so are paired.\n",
    "\n",
    "## What is a Two Sample t-test?\n",
    "A two-sample t-test is used when you want to compare two independent groups to see if their means are different.\n",
    "\n",
    "Examples of when to run a two sampled t-test:\n",
    "\n",
    "- Comparing the test scores boys and girls (two different independent samples) of a particular class test\n",
    "\n",
    "Reference: [Link](https://www.statisticshowto.com/two-sample-t-test-difference-means/)\n",
    "\n",
    "[Also known as Welch’s unequal variances t-test](https://www.statisticshowto.com/welchs-test-for-unequal-variances/) ???????????????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an F-Test? (var.test)\n",
    "\n",
    "An “F Test” is a catch-all term for any test that uses the F-distribution. In most cases, when people talk about the F-Test, what they are actually talking about is The F-Test to <b>`Compare Two Variances.`</b> However, the f-statistic is used in a variety of tests including regression analysis, the Chow test and the Scheffe Test (a post-hoc ANOVA test).\n",
    "\n",
    "F Test to Compare Two Variances\n",
    "A Statistical F Test uses an F Statistic to compare two variances, s1 and s2, by dividing them. The result is always a positive number (because variances are always positive). The equation for comparing two variances with the f-test is:\n",
    "F = variance_1 / varaiance_2\n",
    "\n",
    "If the variances are equal, the ratio of the variances will equal 1. For example, if you had two data sets with a sample 1 (variance of 10) and a sample 2 (variance of 10), the ratio would be 10/10 = 1.\n",
    "\n",
    "-  Null hypothesis:  `variance_1 / varaiance_2 = 1` i.e., the variances of populations are equal.\n",
    "\n",
    "- Altrenate hypothesis: `variance_1 / varaiance_2 != 0` (or) `variance_1 / varaiance_2 > 0` (or) `variance_1 / varaiance_2 < 0`\n",
    "\n",
    "### Assumptions:\n",
    "Several assumptions are made for the test. \n",
    "- Your population must be approximately normally distributed.\n",
    "- Plus, the samples must be independent events.\n",
    "- The larger variance should always go in the numerator (the top number) to force the test into a right-tailed test. Right-tailed tests are easier to calculate.\n",
    "- For two-tailed tests, divide alpha by 2 before finding the right critical value.\n",
    "- If your degrees of freedom aren’t listed in the F Table, use the larger critical value. This helps to avoid the possibility of Type I errors.\n",
    "\n",
    "Reference with example: [Link](https://www.statisticshowto.com/probability-and-statistics/hypothesis-testing/f-test/) (or) [Link](https://www.itl.nist.gov/div898/handbook/eda/section3/eda359.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bartlett's Test: (to check if variances are equal for more than 2 samples)\n",
    "\n",
    "Purpose: Test for Homogeneity of Variances\n",
    "\n",
    "Bartlett's test is used to test if k samples have equal variances. Equal variances across samples is called homogeneity of variances. Some statistical tests, for example the analysis of variance, assume that variances are equal across groups or samples. The Bartlett test can be used to verify that assumption.\n",
    "\n",
    "### Assumption:\n",
    "- Bartlett's test is sensitive to departures from normality. That is, if your samples come from non-normal distributions, then Bartlett's test may simply be testing for non-normality.\n",
    "- The Levene test is an alternative to the Bartlett test that is less sensitive to departures from normality.\n",
    "\n",
    "### Hypothesis:\n",
    "- Null hypothesis:\t    `σ1^2 = σ2^2 = ... = σk^2`\n",
    "\n",
    "- Alternate hypothesis:\t`σi^2 ≠ σj^2`    for at least one pair (i,j).\n",
    "\n",
    "Test statistic: Chisquared distribution\n",
    "\n",
    "Reference with example: [Link](https://www.itl.nist.gov/div898/handbook/eda/section3/eda357.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Square Test for the Variance: [Link](https://www.itl.nist.gov/div898/handbook/eda/section3/eda358.htm)\n",
    "\n",
    "Is it same as bartlett (also uses chisq distribution) test for 2 sample variance comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degrees of Freedom: What are they?: [Link](https://www.statisticshowto.com/probability-and-statistics/hypothesis-testing/degrees-of-freedom/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anova: (Analysis of variance)\n",
    "\n",
    "### One Way ANOVA:\n",
    "A one way ANOVA is used to compare two means from two independent (unrelated) groups using the F-distribution. The null hypothesis for the test is that the two means are equal. Therefore, a significant result means that the two means are unequal.\n",
    "\n",
    "### Examples of when to use a one way ANOVA:\n",
    "Situation 1: You have a group of individuals randomly split into smaller groups and completing different tasks. For example, you might be studying the effects of tea on weight loss and form three groups: green tea, black tea, and no tea.\n",
    "Situation 2: Similar to situation 1, but in this case the individuals are split into groups based on an attribute they possess. For example, you might be studying leg strength of people according to weight. You could split participants into weight categories (obese, overweight and normal) and measure their leg strength on a weight machine.\n",
    "\n",
    "### Limitations of the One Way ANOVA\n",
    "A one way ANOVA will tell you that at least two groups were different from each other. But it won’t tell you which groups were different. If your test returns a significant f-statistic, you may need to run an ad hoc test (like the Least Significant Difference test) to tell you exactly which groups had a difference in means.\n",
    "\n",
    "#### Reference: [Link](https://www.statisticshowto.com/probability-and-statistics/hypothesis-testing/anova/#OneWayANOVA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-way ANOVA:\n",
    "- Checks if y (1 independent variable) is influenced by x (1 dependent-categorical variable)\n",
    "    - Null hypothesis: `μ1 = μ2 = .... = μn`\n",
    "    \n",
    "    - Alternate hypothesis: `μi ≠ μj for at least one pair (i,j)`\n",
    "\n",
    "\n",
    "- <b>F = Variance between groups / Variance within groups</b>\n",
    "- Higher value results in lower p value (alpha) -- so we reject null hypothesis\n",
    "\n",
    "<b> Interpretation:</b>\n",
    "- If 'F value' is higher, it means Variance between groups > variance within groups. Intuitively variance between groups will be higher if means of each group varies high (not equal). If measns are not equal we reject null hypothesis.\n",
    "- Therefore, as F is higher, p value will be less than 0.05 -- so reject null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
